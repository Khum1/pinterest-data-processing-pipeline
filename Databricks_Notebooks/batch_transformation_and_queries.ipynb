{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f6d6d92-5950-44e4-b60e-157102d896ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Batch Transformation and Queries using Databricks and Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0280eac-d907-42d7-a510-441b07fbd3a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[3]: [FileInfo(path=&#39;dbfs:/FileStore/tables/authentication_credentials.csv&#39;, name=&#39;authentication_credentials.csv&#39;, size=202, modificationTime=1674066475000)]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[3]: [FileInfo(path=&#39;dbfs:/FileStore/tables/authentication_credentials.csv&#39;, name=&#39;authentication_credentials.csv&#39;, size=202, modificationTime=1674066475000)]</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/FileStore/tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e88a74e-46ac-4b37-bdbb-74a41be97a4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###### Run this code to mount the S3 bucket to the databricks notebook. Afterwards this code can be commented out/deleted as it only needs to be run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d734823-29a6-4519-98bf-640da03f1d2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-3060891424582214&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     27</span> SOURCE_URL <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;s3n://{0}:{1}@{2}&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>ACCESS_KEY<span class=\"ansi-blue-fg\">,</span> ENCODED_SECRET_KEY<span class=\"ansi-blue-fg\">,</span> AWS_S3_BUCKET<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     28</span> <span class=\"ansi-red-fg\"># Mount the drive</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 29</span><span class=\"ansi-red-fg\"> </span>dbutils<span class=\"ansi-blue-fg\">.</span>fs<span class=\"ansi-blue-fg\">.</span>mount<span class=\"ansi-blue-fg\">(</span>SOURCE_URL<span class=\"ansi-blue-fg\">,</span> MOUNT_NAME<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/python_shell/dbruntime/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    387</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    388</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 389</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    390</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    391</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n",
       "\n",
       "<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o453.mount.\n",
       ": java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/pinterest_pipeline; nested exception is: \n",
       "\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/pinterest_pipeline\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:128)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:68)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:756)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:776)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:295)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/pinterest_pipeline\n",
       "\tat scala.Predef$.require(Predef.scala:281)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:557)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:925)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:706)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:914)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:565)\n",
       "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:120)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$5(DbfsServerBackend.scala:374)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:470)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:374)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:330)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:568)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:662)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:680)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:470)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:657)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:577)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:568)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:539)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:973)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:884)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$3(JettyServer.scala:512)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$3$adapted(JettyServer.scala:487)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:406)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:55)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:406)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:165)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:487)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:388)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n",
       "\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:83)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:49)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:78)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n",
       "\t... 1 more\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3060891424582214&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     27</span> SOURCE_URL <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;s3n://{0}:{1}@{2}&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>ACCESS_KEY<span class=\"ansi-blue-fg\">,</span> ENCODED_SECRET_KEY<span class=\"ansi-blue-fg\">,</span> AWS_S3_BUCKET<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span> <span class=\"ansi-red-fg\"># Mount the drive</span>\n<span class=\"ansi-green-fg\">---&gt; 29</span><span class=\"ansi-red-fg\"> </span>dbutils<span class=\"ansi-blue-fg\">.</span>fs<span class=\"ansi-blue-fg\">.</span>mount<span class=\"ansi-blue-fg\">(</span>SOURCE_URL<span class=\"ansi-blue-fg\">,</span> MOUNT_NAME<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python_shell/dbruntime/dbutils.py</span> in <span class=\"ansi-cyan-fg\">f_with_exception_handling</span><span class=\"ansi-blue-fg\">(*args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    387</span>                     exc<span class=\"ansi-blue-fg\">.</span>__context__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    388</span>                     exc<span class=\"ansi-blue-fg\">.</span>__cause__ <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-fg\">--&gt; 389</span><span class=\"ansi-red-fg\">                     </span><span class=\"ansi-green-fg\">raise</span> exc\n<span class=\"ansi-green-intense-fg ansi-bold\">    390</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    391</span>             <span class=\"ansi-green-fg\">return</span> f_with_exception_handling\n\n<span class=\"ansi-red-fg\">ExecutionError</span>: An error occurred while calling o453.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/pinterest_pipeline; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/pinterest_pipeline\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:128)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:68)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:756)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:776)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/pinterest_pipeline\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:557)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:925)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:706)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:914)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:565)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:120)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$5(DbfsServerBackend.scala:374)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:470)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:374)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:330)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:568)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:662)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:680)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:470)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:657)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:577)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:568)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:539)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:973)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:884)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$3(JettyServer.scala:512)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$3$adapted(JettyServer.scala:487)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:406)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:55)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:406)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:165)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:487)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:388)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:83)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:49)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:78)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\t... 1 more\n</div>",
       "errorSummary": "java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/pinterest_pipeline; nested exception is: ",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import urllib\n",
    "\n",
    "# Specify file type to be csv\n",
    "file_type = \"csv\"\n",
    "# Indicates file has first row as the header\n",
    "first_row_is_header = \"true\"\n",
    "# Indicates file has comma as the delimeter\n",
    "delimiter = \",\"\n",
    "# Read the CSV file to spark dataframe\n",
    "aws_keys_df = spark.read.format(file_type)\\\n",
    ".option(\"header\", first_row_is_header)\\\n",
    ".option(\"sep\", delimiter)\\\n",
    ".load(\"/FileStore/tables/authentication_credentials.csv\")\n",
    "\n",
    "# Get the AWS access key and secret key from the spark dataframe\n",
    "ACCESS_KEY = aws_keys_df.where(col('User name')=='databricks-user').select('Access key ID').collect()[0]['Access key ID']\n",
    "SECRET_KEY = aws_keys_df.where(col('User name')=='databricks-user').select('Secret access key').collect()[0]['Secret access key']\n",
    "# Encode the secrete key\n",
    "ENCODED_SECRET_KEY = urllib.parse.quote(string=SECRET_KEY, safe=\"\")\n",
    "\n",
    "# AWS S3 bucket name\n",
    "AWS_S3_BUCKET = \"user-0a4e65e909bd-bucket\"\n",
    "# Mount name for the bucket\n",
    "MOUNT_NAME = \"/mnt/pinterest_pipeline\"\n",
    "# Source url\n",
    "SOURCE_URL = \"s3n://{0}:{1}@{2}\".format(ACCESS_KEY, ENCODED_SECRET_KEY, AWS_S3_BUCKET)\n",
    "# Mount the drive\n",
    "dbutils.fs.mount(SOURCE_URL, MOUNT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26debfa6-995b-4079-a829-a335adced2c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Creating the geo_df and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5461444-78d4-4e0b-98ac-f874eaee1a36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "file_location = \"/mnt/pinterest_pipeline/topics/0a4e65e909bd.geo/partition=0/*.json\"\n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "geo_df = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location)\n",
    "\n",
    "geo_df = geo_df.withColumn(\"coordinates\", array(col(\"longitude\"), col(\"latitude\")))\n",
    "\n",
    "geo_df = geo_df.withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    "\n",
    "column_structure = [\"ind\", \"country\", \"coordinates\", \"timestamp\"]\n",
    "geo_df = geo_df.select(column_structure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66ee6e35-695c-4bd7-a097-9004fa8eb104",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Creating the pin_df and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39529ca0-c6b5-436a-95ce-227331577a27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_location = \"/mnt/pinterest_pipeline/topics/0a4e65e909bd.pin/partition=0/*.json\"\n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "pin_df = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location)\n",
    "\n",
    "pin_df = pin_df.replace(\"No description available Story format\", None)\n",
    "pin_df = pin_df.replace(\"null\", None)\n",
    "pin_df = pin_df.replace(\"User Info Error\", None)\n",
    "pin_df = pin_df.replace(\"Image src error.\", None)\n",
    "pin_df = pin_df.replace(\"No Title Data Available\", None)\n",
    "pin_df = pin_df.replace(\"N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e\", None)\n",
    "\n",
    "pin_df = pin_df.withColumn(\"follower_count\", when(\n",
    "    col(\"follower_count\").rlike(\"\\\\d+k\"), #checks if the value matches a pattern of one or more digits plus the letter k\n",
    "    (regexp_extract(col(\"follower_count\"), \"(\\\\d+)\", 1).cast(\"integer\") * 1000) #extracts the integer from the cells containing k and * 1000\n",
    ").otherwise(col(\"follower_count\").cast(\"integer\"))) #if it doesn't contain a k, it leaves the integer value\n",
    "\n",
    "pin_df = pin_df.withColumn(\"save_location\", regexp_extract(col(\"save_location\"), \"(/data/).*\", 0)) #extracts the save location of the column \n",
    "\n",
    "pin_df = pin_df.withColumnRenamed(\"index\", \"ind\")\n",
    "\n",
    "column_structure = [\"ind\", \"unique_id\", \"title\", \"description\", \"follower_count\", \"poster_name\", \"tag_list\", \"is_image_or_video\", \"image_src\", \"save_location\", \"category\"]\n",
    "pin_df = pin_df.select(column_structure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1de1d22e-3ef1-42c0-a35e-18dabc02b386",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Creating the user_df and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2017016-a5d0-4be5-8021-3724acbc07ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_location = \"/mnt/pinterest_pipeline/topics/0a4e65e909bd.user/partition=0/*.json\"\n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "user_df = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location)\n",
    "\n",
    "user_df = user_df.withColumn(\"user_name\", concat(col(\"first_name\"),col(\"last_name\")))\n",
    "user_df = user_df.drop(\"first_name\", \"last_name\")\n",
    "user_df = user_df.withColumn(\"date_joined\", col(\"date_joined\").cast(\"timestamp\"))\n",
    "\n",
    "column_structure = [\"ind\", \"user_name\", \"age\", \"date_joined\"]\n",
    "user_df = user_df.select(column_structure)\n",
    "# Display Spark dataframe to check its content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e36d4b72-13e9-42ad-8961-337e389cd964",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Functions created to mitigate repeat code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97d5b16f-6dae-41a7-8211-bf8134e7fd82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def join_df(df1, df2):\n",
    "    '''\n",
    "    Joins two databases with the ind column as a common key.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df1 :\n",
    "        a database to be joined\n",
    "    df2 :\n",
    "        a database to be joined\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    joined_database :\n",
    "        a database created by joining db1 and db2 via the ind column\n",
    "    '''\n",
    "    joined_df = df1.join(df2, df1.ind == df2.ind, \"inner\")\n",
    "    return joined_df\n",
    "\n",
    "def create_post_year(df, column):\n",
    "    '''\n",
    "    Reduces the timestamp of a column to just the year\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df :\n",
    "        df in which the column post_year is to be ammended\n",
    "    column : str\n",
    "        the column that is to be changed to post_year\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df :\n",
    "        dataframe with the column showing the post year as an integer\n",
    "    '''\n",
    "    df = df.withColumn(f\"{column}\", df[column].substr(1,4))\n",
    "    df = df.withColumnRenamed(f\"{column}\", \"post_year\")\n",
    "    df = df.withColumn(\"post_year\", col(\"post_year\").cast(\"Integer\"))\n",
    "    return df\n",
    "\n",
    "def create_age_groups(df):\n",
    "    '''\n",
    "    Creates age_group column from the age column\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df :\n",
    "        dataframe for the age column to be turned into age_group\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df :\n",
    "        dataframe with the age_group column added\n",
    "    '''\n",
    "    df = df.withColumn(\"age_group\", when((df.age >= 18) & (df.age <= 24), \"18-24\")\n",
    "                                             .when((df.age >= 25) & (df.age <= 35), \"25-35\")\n",
    "                                             .when((df.age >=36) & (df.age <= 50), \"36-50\")\n",
    "                                             .when(df.age > 50, \"50+\")\n",
    "                                             .otherwise(\"Unknown\"))\n",
    "    return df\n",
    "\n",
    "def find_most_popular_category(df, column):\n",
    "    '''\n",
    "    Finds the most popular category in the dataframe given its relation to another column\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df :\n",
    "        dataframe to finds the most popular category from\n",
    "    column : str\n",
    "        column to compare the most popular category by\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df :\n",
    "        dataframe that shows the most popular category count\n",
    "    '''\n",
    "    df = df.groupBy(column, \"category\").count().withColumnRenamed(\"count\", \"category_count\")\n",
    "    sorted_df = df.orderBy(col(\"category_count\").desc())\n",
    "    df = sorted_df.groupBy(column).agg( #sorting by the column\n",
    "    first(\"category\").alias(\"most_popular_category\"), #gets the data frame from the first/most popular category\n",
    "    first(\"category_count\").alias(\"category_count\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ca4d060-71cd-46a9-a7ee-6b84d96df82d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Most popular category in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f3611f8-e052-4542-be86-81b009c569bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>country</th><th>most_popular_category</th><th>category_count</th></tr></thead><tbody><tr><td>Albania</td><td>mens-fashion</td><td>50</td></tr><tr><td>Anguilla</td><td>home-decor</td><td>1</td></tr><tr><td>Armenia</td><td>diy-and-crafts</td><td>40</td></tr><tr><td>Aruba</td><td>tattoos</td><td>6</td></tr><tr><td>Azerbaijan</td><td>event-planning</td><td>1</td></tr><tr><td>Bulgaria</td><td>finance</td><td>1</td></tr><tr><td>Cambodia</td><td>diy-and-crafts</td><td>1</td></tr><tr><td>Cocos (Keeling) Islands</td><td>vehicles</td><td>4</td></tr><tr><td>Colombia</td><td>finance</td><td>12</td></tr><tr><td>Cote d'Ivoire</td><td>education</td><td>4</td></tr><tr><td>French Guiana</td><td>quotes</td><td>6</td></tr><tr><td>Jamaica</td><td>vehicles</td><td>1</td></tr><tr><td>Maldives</td><td>beauty</td><td>6</td></tr><tr><td>Montenegro</td><td>christmas</td><td>4</td></tr><tr><td>Mozambique</td><td>home-decor</td><td>1</td></tr><tr><td>Sudan</td><td>mens-fashion</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Albania",
         "mens-fashion",
         50
        ],
        [
         "Anguilla",
         "home-decor",
         1
        ],
        [
         "Armenia",
         "diy-and-crafts",
         40
        ],
        [
         "Aruba",
         "tattoos",
         6
        ],
        [
         "Azerbaijan",
         "event-planning",
         1
        ],
        [
         "Bulgaria",
         "finance",
         1
        ],
        [
         "Cambodia",
         "diy-and-crafts",
         1
        ],
        [
         "Cocos (Keeling) Islands",
         "vehicles",
         4
        ],
        [
         "Colombia",
         "finance",
         12
        ],
        [
         "Cote d'Ivoire",
         "education",
         4
        ],
        [
         "French Guiana",
         "quotes",
         6
        ],
        [
         "Jamaica",
         "vehicles",
         1
        ],
        [
         "Maldives",
         "beauty",
         6
        ],
        [
         "Montenegro",
         "christmas",
         4
        ],
        [
         "Mozambique",
         "home-decor",
         1
        ],
        [
         "Sudan",
         "mens-fashion",
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "most_popular_category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "category_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "category_country_df = join_df(pin_df, geo_df)\n",
    "most_popular_category_df = find_most_popular_category(category_country_df, \"country\")\n",
    "\n",
    "display(most_popular_category_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa54c086-ff20-4c77-abff-01d364574226",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Most popular category each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcde89b0-8c9b-48e9-8eb3-2e3ce1afecd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>post_year</th><th>most_popular_category</th><th>category_count</th></tr></thead><tbody><tr><td>2022</td><td>vehicles</td><td>4</td></tr><tr><td>2021</td><td>finance</td><td>13</td></tr><tr><td>2020</td><td>mens-fashion</td><td>50</td></tr><tr><td>2019</td><td>christmas</td><td>49</td></tr><tr><td>2018</td><td>beauty</td><td>6</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2022,
         "vehicles",
         4
        ],
        [
         2021,
         "finance",
         13
        ],
        [
         2020,
         "mens-fashion",
         50
        ],
        [
         2019,
         "christmas",
         49
        ],
        [
         2018,
         "beauty",
         6
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "post_year",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "most_popular_category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "category_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "post_year_geo_df = create_post_year(geo_df, \"timestamp\")\n",
    "post_year_category_df = join_df(post_year_geo_df, pin_df)\n",
    "post_year_category_df = find_most_popular_category(post_year_category_df, \"post_year\")\n",
    "post_year_category_filtered_df = post_year_category_df.filter((col(\"post_year\") >= 2018) & (col(\"post_year\")<= 2022))\n",
    "most_popualr_category_by_year_df = post_year_category_filtered_df.orderBy(col(\"post_year\").desc())\n",
    "\n",
    "display(most_popualr_category_by_year_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a24fa159-8a3d-4d15-a6ec-3878728cb9e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "User with most followers in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb5d342-3daa-4a48-9996-707eb2b17507",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>country</th><th>follower_count</th><th>poster_name</th></tr></thead><tbody><tr><td>Albania</td><td>null</td><td>null</td></tr><tr><td>Anguilla</td><td>92000</td><td>Kristen | Lifestyle, Mom Tips & Teacher Stuff Blog</td></tr><tr><td>Armenia</td><td>124000</td><td>Of Life & Lisa | Lifestyle Blog</td></tr><tr><td>Aruba</td><td>211000</td><td>TheTrendSpotter</td></tr><tr><td>Azerbaijan</td><td>null</td><td>Style Me Pretty</td></tr><tr><td>Bulgaria</td><td>26000</td><td>Living Low Key | Save Money, Make Money, & Frugal Living</td></tr><tr><td>Cambodia</td><td>6000</td><td>Mixed Media Crafts</td></tr><tr><td>Cocos (Keeling) Islands</td><td>437</td><td>Ray Uyemura</td></tr><tr><td>Colombia</td><td>0</td><td>Consuelo Aguirre</td></tr><tr><td>Cote d'Ivoire</td><td>192000</td><td>The Crafting Chicks</td></tr><tr><td>French Guiana</td><td>51000</td><td>Commitment Connection</td></tr><tr><td>Jamaica</td><td>8000</td><td>hobbyDB</td></tr><tr><td>Maldives</td><td>43000</td><td>Thrive Causemetics</td></tr><tr><td>Montenegro</td><td>79000</td><td>Life Over C's</td></tr><tr><td>Mozambique</td><td>83000</td><td>Stylin by Aylin</td></tr><tr><td>Sudan</td><td>940</td><td>iElylike ..✿◕‿◕✿ஐ✿◕‿◕✿</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Albania",
         null,
         null
        ],
        [
         "Anguilla",
         92000,
         "Kristen | Lifestyle, Mom Tips & Teacher Stuff Blog"
        ],
        [
         "Armenia",
         124000,
         "Of Life & Lisa | Lifestyle Blog"
        ],
        [
         "Aruba",
         211000,
         "TheTrendSpotter"
        ],
        [
         "Azerbaijan",
         null,
         "Style Me Pretty"
        ],
        [
         "Bulgaria",
         26000,
         "Living Low Key | Save Money, Make Money, & Frugal Living"
        ],
        [
         "Cambodia",
         6000,
         "Mixed Media Crafts"
        ],
        [
         "Cocos (Keeling) Islands",
         437,
         "Ray Uyemura"
        ],
        [
         "Colombia",
         0,
         "Consuelo Aguirre"
        ],
        [
         "Cote d'Ivoire",
         192000,
         "The Crafting Chicks"
        ],
        [
         "French Guiana",
         51000,
         "Commitment Connection"
        ],
        [
         "Jamaica",
         8000,
         "hobbyDB"
        ],
        [
         "Maldives",
         43000,
         "Thrive Causemetics"
        ],
        [
         "Montenegro",
         79000,
         "Life Over C's"
        ],
        [
         "Mozambique",
         83000,
         "Stylin by Aylin"
        ],
        [
         "Sudan",
         940,
         "iElylike ..✿◕‿◕✿ஐ✿◕‿◕✿"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "follower_count",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "poster_name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "country_poster_name_follower_df = join_df(pin_df, geo_df)\n",
    "country_poster_name_follower_df = country_poster_name_follower_df.dropDuplicates([\"country\", \"poster_name\", \"follower_count\"])\n",
    "country_poster_name_follower_df = country_poster_name_follower_df.select(\"country\", \"poster_name\", \"follower_count\")\n",
    "\n",
    "country_poster_name_follower_df = country_poster_name_follower_df.orderBy(col(\"follower_count\").desc())\n",
    "most_followers_by_country_df = country_poster_name_follower_df.groupBy(\"country\").agg(\n",
    "    first(\"follower_count\").alias(\"follower_count\"),\n",
    "    first(\"poster_name\").alias(\"poster_name\")\n",
    ")\n",
    "\n",
    "display(most_followers_by_country_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d17468d6-84bd-4250-8040-b14c9edc7eba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "User with most followers overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d97dd6a4-9257-4882-bb92-bd9c4f2c79f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>country</th><th>follower_count</th></tr></thead><tbody><tr><td>Aruba</td><td>211000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Aruba",
         211000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "follower_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "most_followers_country_df = country_poster_name_follower_df.orderBy(col(\"follower_count\").desc())\n",
    "most_followers_country_df = most_followers_country_df.drop(\"poster_name\")\n",
    "most_followers_overall_df = most_followers_country_df.head(1)\n",
    "\n",
    "display(most_followers_overall_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea2be059-e13b-4750-bbd7-ac5a96c2dcf8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Most popular category for each age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bb5a94e-1f15-4041-95f0-eba06eb684f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>age_group</th><th>category</th><th>category_count</th></tr></thead><tbody><tr><td>18-24</td><td>mens-fashion</td><td>46</td></tr><tr><td>25-35</td><td>diy-and-crafts</td><td>36</td></tr><tr><td>36-50</td><td>finance</td><td>9</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "18-24",
         "mens-fashion",
         46
        ],
        [
         "25-35",
         "diy-and-crafts",
         36
        ],
        [
         "36-50",
         "finance",
         9
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "age_group",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "category_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined_pin_user_df = join_df(pin_df, user_df)\n",
    "category_age_df = joined_pin_user_df.select(\"category\", \"age\")\n",
    "category_age_df = create_age_groups(category_age_df)\n",
    "grouped_category_age_df = category_age_df.groupBy(\"category\", \"age_group\").count().withColumnRenamed(\"count\", \"category_count\")\n",
    "grouped_category_age_df = grouped_category_age_df.orderBy(col(\"category_count\").desc())\n",
    "most_popular_category_by_age_group_df = grouped_category_age_df.groupBy(\"age_group\").agg(\n",
    "    first(\"category\").alias(\"category\"),\n",
    "    first(\"category_count\").alias(\"category_count\")\n",
    ")\n",
    "\n",
    "display(most_popular_category_by_age_group_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "859e0f36-5ddb-4b8f-8d93-75df162f4f02",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Median follower count for each age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8a7b786-8cb4-4e19-b53d-ae4fd4124198",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>age_group</th><th>median_follower_count</th></tr></thead><tbody><tr><td>18-24</td><td>211000</td></tr><tr><td>25-35</td><td>79000</td></tr><tr><td>36-50</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "18-24",
         211000
        ],
        [
         "25-35",
         79000
        ],
        [
         "36-50",
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "age_group",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "median_follower_count",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined_pin_user_df = pin_df.join(user_df, pin_df.ind == user_df.ind, \"inner\")\n",
    "follower_age_df = joined_pin_user_df.select(\"follower_count\", \"age\")\n",
    "follower_age_df = create_age_groups(follower_age_df)\n",
    "\n",
    "age_group_median_df = follower_age_df.groupBy(\"age_group\").agg(expr(\"percentile_approx(follower_count, 0.5)\").alias(\"median_follower_count\"))\n",
    "age_group_median_df = age_group_median_df.orderBy(col(\"age_group\").asc())\n",
    "\n",
    "display(age_group_median_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74dad3aa-d45f-4426-a50b-78f0719b8d8b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Number of users joined each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52ca6d87-18ed-4469-bf71-56aff5004144",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>post_year</th><th>number_users_joined</th></tr></thead><tbody><tr><td>2015</td><td>23</td></tr><tr><td>2016</td><td>12</td></tr><tr><td>2017</td><td>10</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2015,
         23
        ],
        [
         2016,
         12
        ],
        [
         2017,
         10
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "post_year",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "number_users_joined",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "users_joined_2015_2020 = create_post_year(user_df, \"date_joined\")\n",
    "users_joined_2015_2020 = users_joined_2015_2020.groupBy(\"post_year\").count().withColumnRenamed(\"count\",\"number_users_joined\")\n",
    "users_joined_2015_2020 = users_joined_2015_2020.orderBy(col(\"post_year\").asc())\n",
    "\n",
    "display(users_joined_2015_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6dcd9e9-33ca-486e-9483-f6e693a3bf22",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Median follower count for users based on their join year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9734df42-717c-48bf-ac11-b32d764fa375",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>post_year</th><th>median_follower_count</th></tr></thead><tbody><tr><td>2015</td><td>25000</td></tr><tr><td>2016</td><td>124000</td></tr><tr><td>2017</td><td>79000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2015,
         25000
        ],
        [
         2016,
         124000
        ],
        [
         2017,
         79000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "post_year",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "median_follower_count",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pin_user_df = join_df(pin_df, user_df)\n",
    "post_date_follower_df = pin_user_df.select(\"date_joined\", \"follower_count\")\n",
    "post_year_follower_df = create_post_year(post_date_follower_df, \"date_joined\")\n",
    "\n",
    "year_follower_median_df = post_year_follower_df.groupBy(\"post_year\").agg(expr(\"percentile_approx(follower_count, 0.5)\").alias(\"median_follower_count\"))\n",
    "\n",
    "display(year_follower_median_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb6366db-2eba-4b88-8b58-ad2335fb73ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Median follower count based on age group and join year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f27857f5-2fc1-41c2-974a-4146fb9a381b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>age_group</th><th>post_year</th><th>median_follower_count</th></tr></thead><tbody><tr><td>18-24</td><td>2015</td><td>211000</td></tr><tr><td>18-24</td><td>2017</td><td>940</td></tr><tr><td>25-35</td><td>2015</td><td>51000</td></tr><tr><td>25-35</td><td>2016</td><td>124000</td></tr><tr><td>25-35</td><td>2017</td><td>79000</td></tr><tr><td>36-50</td><td>2015</td><td>25000</td></tr><tr><td>36-50</td><td>2017</td><td>6000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "18-24",
         2015,
         211000
        ],
        [
         "18-24",
         2017,
         940
        ],
        [
         "25-35",
         2015,
         51000
        ],
        [
         "25-35",
         2016,
         124000
        ],
        [
         "25-35",
         2017,
         79000
        ],
        [
         "36-50",
         2015,
         25000
        ],
        [
         "36-50",
         2017,
         6000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "age_group",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "post_year",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "median_follower_count",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pin_user_df = join_df(pin_df, user_df)\n",
    "follower_age_date_df = pin_user_df.select(\"follower_count\", \"age\", \"date_joined\")\n",
    "follower_age_date_df = create_age_groups(follower_age_date_df)\n",
    "follower_age_year_df = follower_age_date_df.drop(\"age\")\n",
    "follower_age_year_df = create_post_year(follower_age_date_df, \"date_joined\")\n",
    "\n",
    "follower_age_year_median_df = follower_age_year_df.groupBy(\"age_group\", \"post_year\").agg(expr(\"percentile_approx(follower_count, 0.5)\").alias(\"median_follower_count\"))\n",
    "follower_age_year_median_df = follower_age_year_median_df.sort([\"age_group\", \"post_year\"], ascending = True)\n",
    "\n",
    "display(follower_age_year_median_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "585d6824-ed8a-4820-9385-a499ae4d71e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "batch_transformation_and_queries",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
